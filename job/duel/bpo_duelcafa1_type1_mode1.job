# template for an evaluation pipeline job

# output
# ------
# 1. sequence-centric assessment
#		 top10-model curve
#		 top10-model bar
#		 all-model sheets (NA and A)
#
# 2. term-centric assessment
#		 all-term histogram
#		 top20-/bottom20-term boxplot
#		 all-term sheet (NA and A)

# paths
# -----
# where is the parsed 'pred' structures
pred_dir   = ~/cv3/duel/cafa1/prediction/bpo/

# where is pre-computed results?
prev_dir   = ~/cv3/duel/cafa1/seq-centric/bpo/

# where to put output folder
eval_dir   = ~/cv3/duel/cafa1/evaluation/

# where is the annotation structure
annotation = ~/cv3/duel/cafa1/benchmark/groundtruth/bpoa.mat

# benchmark list file
benchmark  = ~/cv3/duel/cafa1/benchmark/bpo_duel_type1.txt

# where is the bootstrap index
bootstrap  = ~/cv3/config/bootstrap/bpo_duel_type1.mat

# ontology
# --------
# options: mfo, bpo, cco, hpo
ontology = bpo

# benchmark category
# ------------------
# options: all, easy, hard, eukarya, prokarya, species
category = duel

# type
# ----
# options: 1, 2
type = 1

# mode
# ----
# options: 1, 2
mode = 1

# metric
# ------
# options:
# f (F1-max), s (S2-min), wf (weighted F1-max), ns (normalized S2-min), auc
metric = f
metric = wf
metric = s
metric = ns
metric = auc

# model
# -----
# options: all (all regular models), +M*, -M*, +B*, -B* 
# baseline (Naive/BLAST) options: B[NB][14][SGUA]
# note: B[NB]4S is the most typical, which was trained on SwissProt Jan.2014
model = all

# -------------
# Yuxiang Jiang (yuxjiang@indiana.edu)
# Department of Computer Science
# Indiana University, Bloomington
# Last modified: Wed 10 Jun 2015 04:34:52 PM E
