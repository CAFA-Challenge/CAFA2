# template for an evaluation pipeline job

# paths
# -----
# where is the parsed 'pred' structures
pred_dir   = ~/cafa/duel/cafa2/prediction/bpo/

# where is pre-computed results?
prev_dir   = ~/cafa/duel/cafa2/seq-centric/bpo/

# where to put output folder
eval_dir   = ~/cafa/duel/cafa2/evaluation/

# where is the annotation structure
annotation = ~/cafa/duel/cafa2/benchmark/groundtruth/bpoa.mat

# benchmark list file
benchmark  = ~/cafa/duel/cafa2/benchmark/lists/bpo_duel_type1.txt

# where is the bootstrap index
bootstrap  = ~/cafa/config/bootstrap/bpo_duel_type1.mat

# ontology
# --------
# options: mfo, bpo, cco, hpo
ontology = bpo

# benchmark category
# ------------------
# options: all, easy, hard, eukarya, prokarya, species
category = duel

# type
# ----
# options: 1, 2
type = 1

# mode
# ----
# options: 1, 2
mode = 1

# metric
# ------
# options:
# f (F1-max), s (S2-min), wf (weighted F1-max), ns (normalized S2-min), auc
metric = f
# metric = wf
# metric = s
# metric = ns
# metric = auc

# model
# -----
# options: all (all regular models), +M*, -M*, +B*, -B* 
# baseline (Naive/BLAST) options: B[NB][14][SGUA]
# note: B[NB]4S is the most typical, which was trained on SwissProt Jan.2014
model = all

# -------------
# Yuxiang Jiang (yuxjiang@indiana.edu)
# Department of Computer Science
# Indiana University, Bloomington
# Last modified: Wed 17 Feb 2016 12:43:26 AM E
